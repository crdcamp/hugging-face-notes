{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff8ef6d",
   "metadata": {},
   "source": [
    "# Agent Using smolagents\n",
    "\n",
    "In the last section, we learned how we can create Agents from scratch using Python code, and we saw just how tedious that process can be. Fortunately, many Agent libraries simplify this work by handling much of the heavy lifting for you.\n",
    "\n",
    "In this tutorial, you’ll create your very first Agent capable of performing actions such as image generation, web search, time zone checking and much more!\n",
    "\n",
    "You will also publish your agent on a Hugging Face Space so you can share it with friends and colleagues.\n",
    "\n",
    "Let’s get started!\n",
    "\n",
    "## What is smolagents?\n",
    "\n",
    "`smolagents` is a library that provides a framework for developing your agents with ease. It's designed for simplicity and abstracts away much of the complexity of building an Agent.\n",
    "\n",
    "**In short, `smolagents` is a library that focuses on codeAgent, a kind of agent that performs “Actions” through code blocks, and then “Observes” results by executing the code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd9332a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, FinalAnswerTool, InferenceClientModel, load_tool, tool\n",
    "import datetime\n",
    "import requests\n",
    "import pytz\n",
    "import yaml\n",
    "import gradio\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HF_INF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ddc5ac",
   "metadata": {},
   "source": [
    "We will directly use the CodeAgent class from `smolagents`.\n",
    "\n",
    "**The Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecd67819",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def my_custom_tool(arg1:str, arg2:int)-> str: # it's important to specify the return type\n",
    "    # Keep this format for the tool description / args description but feel free to modify the tool\n",
    "    \"\"\"A tool that does nothing yet \n",
    "    Args:\n",
    "        arg1: the first argument\n",
    "        arg2: the second argument\n",
    "    \"\"\"\n",
    "    return \"What magic will you build ?\"\n",
    "\n",
    "@tool\n",
    "def get_current_time_in_timezone(timezone: str) -> str:\n",
    "    \"\"\"A tool that fetches the current local time in a specified timezone.\n",
    "    Args:\n",
    "        timezone: A string representing a valid timezone (e.g., 'America/New_York').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create timezone object\n",
    "        tz = pytz.timezone(timezone)\n",
    "        # Get current time in that timezone\n",
    "        local_time = datetime.datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        return f\"The current local time in {timezone} is: {local_time}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching time for timezone '{timezone}': {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d75a3",
   "metadata": {},
   "source": [
    "So far we have:\n",
    "1. A non-working dummy Tool that you can modify to make something useful.\n",
    "1. An actually working Tool that gets the current time somewhere in the world.\n",
    "\n",
    "To define your tool it's important to:\n",
    "1. Provide input and output types for your function\n",
    "1. A well formatted docstring. `smolagents` is expecting all the arguments to have a textual description in the docstring.\n",
    "\n",
    "## The Agent\n",
    "\n",
    "It uses Qwen/Qwen2.5-Coder-32B-Instruct as the LLM engine. This is a very capable model that we’ll access via the serverless API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "687f79d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Some prompt templates are missing from your custom `prompt_templates`: {'final_answer'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     prompt_templates = yaml.safe_load(stream)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# We're creating our CodeAgent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m agent = \u001b[43mCodeAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfinal_answer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# add your tools here (don't remove final_answer)\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbosity_level\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#grammar=None, I think the example is outdated. Says \"grammer is an unecpected argument\". Probably can fix with the full example\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplanning_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_templates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_templates\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m GradioUI(agent).launch()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging-face-notes/hugging-env/lib/python3.13/site-packages/smolagents/agents.py:1542\u001b[39m, in \u001b[36mCodeAgent.__init__\u001b[39m\u001b[34m(self, tools, model, prompt_templates, additional_authorized_imports, planning_interval, executor_type, executor_kwargs, max_print_outputs_length, stream_outputs, use_structured_outputs_internally, code_block_tags, **kwargs)\u001b[39m\n\u001b[32m   1533\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mOnly \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmarkdown\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is supported for a string argument to `code_block_tags`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1534\u001b[39m \u001b[38;5;28mself\u001b[39m.code_block_tags = (\n\u001b[32m   1535\u001b[39m     code_block_tags\n\u001b[32m   1536\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(code_block_tags, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33m<code>\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m</code>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1540\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1542\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_templates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_templates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplanning_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplanning_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28mself\u001b[39m.stream_outputs = stream_outputs\n\u001b[32m   1550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_outputs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mgenerate_stream\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging-face-notes/hugging-env/lib/python3.13/site-packages/smolagents/agents.py:316\u001b[39m, in \u001b[36mMultiStepAgent.__init__\u001b[39m\u001b[34m(self, tools, model, prompt_templates, instructions, max_steps, add_base_tools, verbosity_level, managed_agents, step_callbacks, planning_interval, name, description, provide_run_summary, final_answer_checks, return_full_result, logger)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompt_templates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    315\u001b[39m     missing_keys = \u001b[38;5;28mset\u001b[39m(EMPTY_PROMPT_TEMPLATES.keys()) - \u001b[38;5;28mset\u001b[39m(prompt_templates.keys())\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_keys, (\n\u001b[32m    317\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSome prompt templates are missing from your custom `prompt_templates`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    318\u001b[39m     )\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m EMPTY_PROMPT_TEMPLATES.items():\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[31mAssertionError\u001b[39m: Some prompt templates are missing from your custom `prompt_templates`: {'final_answer'}"
     ]
    }
   ],
   "source": [
    "final_answer = FinalAnswerTool()\n",
    "model = InferenceClientModel(\n",
    "    max_tokens=2096,\n",
    "    temperature=0.5,\n",
    "    model_id='Qwen/Qwen2.5-Coder-32B-Instruct',\n",
    "    custom_role_conversions=None,\n",
    ")\n",
    "\n",
    "with open(\"prompts.yaml\", 'r') as stream:\n",
    "    prompt_templates = yaml.safe_load(stream)\n",
    "    \n",
    "# We're creating our CodeAgent\n",
    "agent = CodeAgent(\n",
    "    model=model,\n",
    "    tools=[final_answer], # add your tools here (don't remove final_answer)\n",
    "    max_steps=6,\n",
    "    verbosity_level=1,\n",
    "    #grammar=None, I think the example is outdated. Says \"grammer is an unecpected argument\". Probably can fix with the full example\n",
    "    planning_interval=None,\n",
    "    name=None,\n",
    "    description=None,\n",
    "    prompt_templates=prompt_templates\n",
    ")\n",
    "\n",
    "GradioUI(agent).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce109d1",
   "metadata": {},
   "source": [
    "Due to issues with the dependencies present in the actual template, I'm stopping here and resuming on the template."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
