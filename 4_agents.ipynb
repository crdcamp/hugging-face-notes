{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a8c0ed4",
   "metadata": {},
   "source": [
    "# Introduction to Agents\n",
    "\n",
    "Your Agent, named Alfred, will handle a simple task and demonstrate how to apply these concepts in practice.\n",
    "\n",
    "## What is an Agent?\n",
    "\n",
    "Think of the Agent as having two main parts:\n",
    "\n",
    "1. The Brain (AI Model)\n",
    "\n",
    "This is where all the thinking happens. The AI model handles reasoning and planning. It decides which Actions to take based on the situation.\n",
    "\n",
    "2. The Body (Capabilities and Tools)\n",
    "\n",
    "This part represents everything the Agent is equipped to do.\n",
    "\n",
    "The scope of possible actions depends on what the agent has been equipped with. For example, because humans lack wings, they can’t perform the “fly” Action, but they can execute Actions like “walk”, “run” ,“jump”, “grab”, and so on.\n",
    "\n",
    "## What type of AI Models do we use for Agents?\n",
    "\n",
    "The most common AI model found in Agents is an LLM (Large Language Model), which takes Text as an input and outputs Text as well.\n",
    "\n",
    "Well known examples are GPT4 from OpenAI, LLama from Meta, Gemini from Google, etc. These models have been trained on a vast amount of text and are able to generalize well. We will learn more about LLMs in the next section.\n",
    "\n",
    "## What type of tasks can an Agent do?\n",
    "\n",
    "An Agent can perform any task we implement via Tools to complete Actions.\n",
    "\n",
    "For example, if I write an Agent to act as my personal assistant (like Siri) on my computer, and I ask it to “send an email to my Manager asking to delay today’s meeting”, I can give it some code to send emails. This will be a new Tool the Agent can use whenever it needs to send an email. We can write it in Python:\n",
    "\n",
    "```python\n",
    "def send_message_to(recipient, message):\n",
    "    \"\"\"Useful to send an e-mail message to a recipient\"\"\"\n",
    "```\n",
    "\n",
    "The LLM, as we’ll see, will generate code to run the tool when it needs to, and thus fulfill the desired task.\n",
    "\n",
    "The design of the Tools is very important and has a great impact on the quality of your Agent. Some tasks will require very specific Tools to be crafted, while others may be solved with general purpose tools like “web_search”.\n",
    "\n",
    "Allowing an agent to interact with its environment allows real-life usage for companies and individuals.\n",
    "\n",
    "1. Encoders\n",
    "\n",
    "An encoder-based Transformer takes text (or other data) as input and outputs a dense representation (or embedding) of that text.\n",
    "\n",
    "* Example: BERT from Google\n",
    "* Use Cases: Text classification, semantic search, Named Entity Recognition\n",
    "* Typical Size: Millions of parameters\n",
    "\n",
    "2. Decoders\n",
    "\n",
    "A decoder-based Transformer focuses on generating new tokens to complete a sequence, one token at a time.\n",
    "\n",
    "* Example: Llama from Meta\n",
    "* Use Cases: Text generation, chatbots, code generation\n",
    "* Typical Size: Billions (in the US sense, i.e., 10^9) of parameters\n",
    "\n",
    "3. Seq2Seq (Encoder–Decoder)\n",
    "\n",
    "A sequence-to-sequence Transformer combines an encoder and a decoder. The encoder first processes the input sequence into a context representation, then the decoder generates an output sequence.\n",
    "\n",
    "* Example: T5, BART\n",
    "* Use Cases: Translation, Summarization, Paraphrasing\n",
    "* Typical Size: Millions of parameters\n",
    "\n",
    "Although Large Language Models come in various forms, LLMs are typically decoder-based models with billions of parameters. Here are some of the most well-known LLMs:\n",
    "\n",
    "The underlying principle of an LLM is simple yet highly effective: its objective is to predict the next token, given a sequence of previous tokens. A “token” is the unit of information an LLM works with. You can think of a “token” as if it was a “word”, but for efficiency reasons LLMs don’t use whole words.\n",
    "\n",
    "Each LLM has some special tokens specific to the model. The LLM uses these tokens to open and close the structured components of its generation. For example, to indicate the start or end of a sequence, message, or response. Moreover, the input prompts that we pass to the model are also structured with special tokens. The most important of those is the End of sequence token (EOS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202133aa",
   "metadata": {},
   "source": [
    "# Messages and Special Tokens\n",
    "\n",
    "Now that we understand how LLMs work, let’s look at how they structure their generations through chat templates.\n",
    "\n",
    "Just like with ChatGPT, users typically interact with Agents through a chat interface. Therefore, we aim to understand how LLMs manage chats.\n",
    "\n",
    "Up until now, we’ve discussed prompts as the sequence of tokens fed into the model. But when you chat with systems like ChatGPT or HuggingChat, you’re actually exchanging messages. Behind the scenes, these messages are concatenated and formatted into a prompt that the model can understand.\n",
    "\n",
    "This is where chat templates come in. They act as the bridge between conversational messages (user and assistant turns) and the specific formatting requirements of your chosen LLM. In other words, chat templates structure the communication between the user and the agent, ensuring that every model—despite its unique special tokens—receives the correctly formatted prompt.\n",
    "\n",
    "## Messages: The Underlying System of LLMs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
